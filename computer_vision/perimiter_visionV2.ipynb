{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catanomics - Computer Vision and pre-processing\n",
    "The goal of this notebook is to read in an image of a catan board without number or settlements, and draw the board (ports not included) over the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image function for later use\n",
    "def showImage(img, name=None):\n",
    "    if not name:\n",
    "        cv2.imshow(\"Image display\", img)\n",
    "    else:\n",
    "        cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# Save image function\n",
    "def saveImage(filename, img, dir):\n",
    "    # Get full path\n",
    "    full_path = f\"{dir}/{filename}\"\n",
    "    cv2.imwrite(full_path, img)\n",
    "    print(f\"Image saved to {full_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in the image, detect the border, and find the max/min y point of the permiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 16:30:08.195 Python[26042:4025130] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    }
   ],
   "source": [
    "# Read in an image\n",
    "# image = cv2.imread('../images/v0/catan01q.jpg')\n",
    "image = cv2.imread('../images/v4/board00.jpg')\n",
    "# The input imgs are too big, so reduce to 25%\n",
    "image = cv2.resize(image, (1052,1052))\n",
    "showImage(image)\n",
    "og_img = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to hsv\n",
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color bounds for the perimiter of the board\n",
    "lower_blue = np.array([100, 150, 0])\n",
    "upper_blue = np.array([140, 255, 255])\n",
    "\n",
    "# # This is for beige instead of blue (EXPERIMENT)\n",
    "# upper_blue = np.array([174, 242, 251])\n",
    "# lower_blue = np.array([49, 145, 174])\n",
    "\n",
    "# Create a binary mask where the blue regions are white, and everything else is black\n",
    "mask = cv2.inRange(hsv_image, lower_blue, upper_blue)\n",
    "# showImage(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bitwise AND to keep the blue parts of the image\n",
    "blue_regions = cv2.bitwise_and(image, image, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Perform canny edge detection on the blue_regions\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_blue_region = cv2.cvtColor(blue_regions, cv2.COLOR_BGR2GRAY)\n",
    "# Apply Gaussian Blur\n",
    "blurred_blue_regions = cv2.GaussianBlur(gray_blue_region, (5,5), 0)\n",
    "# Canny edge detection\n",
    "edges = cv2.Canny(blurred_blue_regions, 50, 150)\n",
    "# Show the result\n",
    "showImage(edges, \"Edges in blue regions\")\n",
    "\n",
    "# 729.24435816, 601.65764162\n",
    "print(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform Hough Transform on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "Trying threshold 200 | Got 3 lines.\n",
      "3\n",
      "Trying threshold 195 | Got 3 lines.\n",
      "3\n",
      "Trying threshold 190 | Got 3 lines.\n",
      "3\n",
      "Trying threshold 185 | Got 3 lines.\n",
      "4\n",
      "Trying threshold 180 | Got 4 lines.\n",
      "4\n",
      "Trying threshold 175 | Got 4 lines.\n",
      "5\n",
      "Trying threshold 170 | Got 5 lines.\n",
      "5\n",
      "Trying threshold 165 | Got 5 lines.\n",
      "6\n",
      "Trying threshold 160 | Got 6 lines.\n",
      "6\n",
      "Trying threshold 155 | Got 6 lines.\n",
      "6\n",
      "Trying threshold 150 | Got 6 lines.\n",
      "7\n",
      "Trying threshold 145 | Got 7 lines.\n",
      "7\n",
      "Trying threshold 140 | Got 7 lines.\n",
      "7\n",
      "Trying threshold 135 | Got 7 lines.\n",
      "7\n",
      "Trying threshold 130 | Got 7 lines.\n",
      "7\n",
      "Trying threshold 125 | Got 7 lines.\n",
      "9\n",
      "Trying threshold 120 | Got 9 lines.\n",
      "10\n",
      "Trying threshold 115 | Got 10 lines.\n",
      "Results: 115 threshold | 10 lines\n"
     ]
    }
   ],
   "source": [
    "# Perform Hough Transform using `HoughLines`\n",
    "lines = []\n",
    "thresh = 200\n",
    "print(len(lines))\n",
    "while len(lines) < 10:\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, thresh)\n",
    "    print(len(lines))\n",
    "    print(f\"Trying threshold {thresh} | Got {len(lines)} lines.\")\n",
    "    if len(lines) >= 10:\n",
    "        break\n",
    "    else:\n",
    "        thresh -= 5\n",
    "print(f\"Results: {thresh} threshold | {len(lines)} lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw lines on the image\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    \n",
    "showImage(image)\n",
    "# saveImage(\"perimiter00.jpg\", image, \"../images/perimiter/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "Overlapping indexes: {8, 9, 5, 7}\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "min_rho_difference = 10\n",
    "overlapping_indexes = set()\n",
    "\n",
    "while len(lines) - len(overlapping_indexes) > 6:\n",
    "    for i in range(len(lines)):\n",
    "        rho, _ = lines[i, 0]\n",
    "        for j in range(i+1, len(lines)):\n",
    "            rho2, _ = lines[j, 0]\n",
    "            if abs(rho - rho2) < min_rho_difference:\n",
    "                overlapping_indexes.add(j)\n",
    "    min_rho_difference+=1\n",
    "    print(len(overlapping_indexes))\n",
    "print(f\"Overlapping indexes: {overlapping_indexes}\")\n",
    "print(len(lines) - len(overlapping_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "perimiter_lines = []\n",
    "for i in range(len(lines)):\n",
    "    if i not in overlapping_indexes:\n",
    "        perimiter_lines.append(lines[i])\n",
    "        \n",
    "print(len(perimiter_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates of line 0: ((-662, 827)) to ((1034, -232))\n",
      "Coordinates of line 1: ((-69, -1114)) to ((930, 617))\n",
      "Coordinates of line 2: ((-1160, 335)) to ((741, 953))\n",
      "Coordinates of line 3: ((261, 1404)) to ((1409, -234))\n",
      "Coordinates of line 4: ((94, 1006)) to ((199, -990))\n",
      "Coordinates of line 5: ((-997, -110)) to ((965, 271))\n"
     ]
    }
   ],
   "source": [
    "# This is a list of lists of tuples which are coordinates for each line\n",
    "line_coords = []\n",
    "# Calculate start and end points for the lines\n",
    "for index, line in enumerate(perimiter_lines):\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(og_img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    print(f\"Coordinates of line {index}: ({x1, y1}) to ({x2, y2})\")\n",
    "    line_coords.append([(x1, y1), (x2, y2)])\n",
    "line_coords[0]\n",
    "showImage(og_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Function to calculate the slope given two points\n",
    "def slope(x1,y1,x2,y2):\n",
    "    ###finding slope\n",
    "    if x2!=x1:\n",
    "        return((y2-y1)/(x2-x1))\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "# Function to calculate the y-intercept given two points \n",
    "def y_intercept(x1,y1,x2,y2):\n",
    "    # y = mx+b OR b = y-mx\n",
    "    b = y1 - int(slope(x1, y1, x2, y2) * x1)\n",
    "    return b\n",
    "\n",
    "def calc_intersection(m1,b1,m2,b2):\n",
    "    # Create the coefficient matrices\n",
    "    a = np.array([[-m1, 1], [-m2, 1]])\n",
    "    b = np.array([b1, b2])\n",
    "    try:\n",
    "        solution = np.linalg.solve(a, b)\n",
    "    except:\n",
    "        solution = (0,0)\n",
    "\n",
    "    return solution\n",
    "\n",
    "# Function that draws the lines in the bounds of the image\n",
    "def drawLine(image,x1,y1,x2,y2):\n",
    "\n",
    "    m=slope(x1,y1,x2,y2)\n",
    "    h,w=image.shape[:2]\n",
    "    if m!='NA':\n",
    "        ## here we are essentially extending the line to x=0 and x=width\n",
    "        ## and calculating the y associated with it\n",
    "        # starting point\n",
    "        px=0\n",
    "        py=-(x1-0)*m+y1\n",
    "        # ending point\n",
    "        qx=w\n",
    "        qy=-(x2-w)*m+y2\n",
    "    else:\n",
    "    # if slope is zero, draw a line with x=x1 and y=0 and y=height\n",
    "        px,py=x1,0\n",
    "        qx,qy=x1,h\n",
    "    # Draws a green line\n",
    "    # cv2.line(image, (int(px), int(py)), (int(qx), int(qy)), (0, 255, 0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(-662, 827), (1034, -232)], [(-69, -1114), (930, 617)], [(-1160, 335), (741, 953)], [(261, 1404), (1409, -234)], [(94, 1006), (199, -990)], [(-997, -110), (965, 271)]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-0.6244103773584906, 414),\n",
       " (1.7327327327327327, -995),\n",
       " (0.3250920568122041, 712),\n",
       " (-1.4268292682926829, 1776),\n",
       " (-19.00952380952381, 2792),\n",
       " (0.19418960244648317, 83)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = og_img.copy()\n",
    "# List of lists of tuples of slope and y-intercept of linear lines\n",
    "line_equations = []\n",
    "print(line_coords)\n",
    "for line in line_coords:\n",
    "    try:\n",
    "        line_equations.append((slope(line[0][0], line[0][1], line[1][0], line[1][1]), y_intercept(line[0][0], line[0][1], line[1][0], line[1][1])))\n",
    "    except:\n",
    "        pass\n",
    "line_equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[597.75751161  40.75400661]\n",
      "[-313.84858983  609.97031641]\n",
      "[1697.36781547 -645.85407818]\n",
      "[129.34377635 333.2364038 ]\n",
      "[404.34889832 161.52035181]\n",
      "[1212.66742941 1106.22854886]\n",
      "[877.02029557 524.6417734 ]\n",
      "[ 182.57415688 -678.64778222]\n",
      "[700.66284057 219.06143846]\n",
      "[607.33320883 909.43920203]\n",
      "[107.57907033 746.97310124]\n",
      "[-4805.10470982  -850.10137331]\n",
      "[  57.78408978 1693.55196946]\n",
      "[1044.40486817  285.81256614]\n",
      "[141.06646678 110.3936411 ]\n",
      "Perimeter points: [(598, 41), (129, 333), (404, 162), (877, 525), (701, 219), (607, 909), (108, 747), (1044, 286), (141, 110)]\n",
      "Length: 9\n"
     ]
    }
   ],
   "source": [
    "# intersection = calc_intersection(line_equations[0][0], line_equations[0][1], line_equations[1][0], line_equations[1][1])\n",
    "# cv2.circle(test_image, (int(intersection[0]), int(intersection[1])), 1, (0, 0, 255), -1)\n",
    "# showImage(test_image)\n",
    "\n",
    "perimeter_points = []\n",
    "image_height, image_width, _ = test_image.shape\n",
    "for ind, line_one in enumerate(line_equations):\n",
    "    for line_two in line_equations[ind+1:]:\n",
    "        perimeter_point = calc_intersection(line_one[0], line_one[1], line_two[0], line_two[1])\n",
    "        print(perimeter_point)\n",
    "        if perimeter_point[0] == 0 and perimeter_point[1] == 0:\n",
    "            print(\"This perimiter point doesnt matter ?!\")\n",
    "        elif perimeter_point[0] >= 0 and perimeter_point[0] <= image_width and perimeter_point[1] >= 0 and perimeter_point[1] <= image_height:\n",
    "            perimeter_points.append((round(perimeter_point[0]), round(perimeter_point[1])))\n",
    "\n",
    "# for i in range(len(line_equations)):\n",
    "#     if i+1 == len(line_equations):\n",
    "#         perimeter_point = calc_intersection(line_equations[i][0], line_equations[i][1], line_equations[0][0], line_equations[0][1])\n",
    "#     else:\n",
    "#         perimeter_point = calc_intersection(line_equations[i][0], line_equations[i][1], line_equations[i+1][0], line_equations[i+1][1])\n",
    "#     perimeter_points.append(perimeter_point)\n",
    "\n",
    "print(f\"Perimeter points: {perimeter_points}\\nLength: {len(perimeter_points)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the cloesest edge points with the coordinates found in the intersections (and setting a max distance so we get rid of non-perimeter points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(perimeter_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Invert the binary image (edges)\n",
    "inverted_edges = 255 - edges\n",
    "\n",
    "# Apply distance transform\n",
    "dist_transform = cv2.distanceTransform(inverted_edges, cv2.DIST_L2, 5)\n",
    "\n",
    "good_pts = []\n",
    "\n",
    "dist_threshold = 25\n",
    "\n",
    "# For each point, find the distance to the closest white pixel\n",
    "while len(good_pts) < 6:\n",
    "    good_pts = []\n",
    "    for i in range(len(perimeter_points)):\n",
    "        x, y = perimeter_points[i]\n",
    "        dist_to_edge = dist_transform[y, x]\n",
    "        if dist_to_edge < dist_threshold:\n",
    "            if len(good_pts) < 6:\n",
    "                good_pts.append(perimeter_points[i])\n",
    "                # perimeter_points = perimeter_points[0:i] + perimeter_points[i+1:]\n",
    "    print(len(good_pts))\n",
    "    dist_threshold += 5\n",
    "good_pts\n",
    "colors = [(0,0,255), (51, 153, 255), (0,255,255), (0,255,0), (255,0,0), (255, 0, 127)]\n",
    "for i in range(len(good_pts)):\n",
    "    pass\n",
    "    # cv2.circle(test_image, (round(good_pts[i][0]), round(good_pts[i][1])), 5, colors[i], -1)\n",
    "# showImage(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "coord: (129, 333) | color: red\n",
      "coord: (404, 162) | color: orange\n",
      "coord: (877, 525) | color: yellow\n",
      "coord: (701, 219) | color: green\n",
      "coord: (607, 909) | color: blue\n",
      "coord: (108, 747) | color: purple\n"
     ]
    }
   ],
   "source": [
    "str_colors = [\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\"]\n",
    "print(len(good_pts), len(str_colors))\n",
    "for i in range(len(good_pts)):\n",
    "    print(f\"coord: {good_pts[i]} | color: {str_colors[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1052, 1052, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order the points via angle from the centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = np.mean(good_pts, axis=0)\n",
    "sorted_points = sorted(good_pts, key=lambda point: np.arctan2(point[1] - centroid[1], point[0] - centroid[0]))\n",
    "for i, point in enumerate(sorted_points):\n",
    "    pass\n",
    "    # cv2.circle(test_image, point, 20, colors[i], -1)\n",
    "\n",
    "# showImage(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1052, 1052, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Homography on the image to get a top down view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(129, 333), (404, 162), (701, 219), (877, 525), (607, 909), (108, 747)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The source points are the perimiter points that have been previously found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_points = np.array(sorted_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The destination points are just a correctly oriented hexagon within the 1052x1052 bounds of the image\n",
    "\n",
    "Things that need to be done to get these points:\n",
    "* calculate the center of the ideal image\n",
    "* make sure the orientation is correct (might need to be rotated 90 degrees)\n",
    "* init the rotation matrix\n",
    "* find the points of a hexagon in a space of the image's dimensions\n",
    "    * `np.array([(center[0] + R * np.cos(2 * np.pi / 6 * i), center[1] + R * np.sin(2 * np.pi / 6 * i)) for i in range(6)])`\n",
    "* add these found *ideal* points to a new list in the correct format\n",
    "* make sure `dst_points` and `src_points` are numpy arrays for `cv2.findHomography()`\n",
    "* use `cv2.findHomography()` to calculate the rotation matrix\n",
    "* use `cv2.warpHomography()` with the src and dst points to get the top-down image of a catan board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center of an ideal image\n",
    "R = 526\n",
    "center = np.array([R, R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle of rotation (this method finds points rotated 90 degrees from where we want them)\n",
    "rotate = True\n",
    "theta = np.pi / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.123234e-17, -1.000000e+00],\n",
       "       [ 1.000000e+00,  6.123234e-17]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init the rotation matrix\n",
    "rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                            [np.sin(theta), np.cos(theta)]])\n",
    "rotation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1052.        ,  526.        ],\n",
       "       [ 789.        ,  981.52936239],\n",
       "       [ 263.        ,  981.52936239],\n",
       "       [   0.        ,  526.        ],\n",
       "       [ 263.        ,   70.47063761],\n",
       "       [ 789.        ,   70.47063761]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the ideal points of a hexagon\n",
    "hexagon_points = np.array([(center[0] + R * np.cos(2 * np.pi / 6 * i), center[1] + R * np.sin(2 * np.pi / 6 * i)) for i in range(6)])\n",
    "hexagon_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 526 1052]\n",
      " [  70  789]\n",
      " [  70  263]\n",
      " [ 525    0]\n",
      " [ 981  262]\n",
      " [ 981  788]]\n"
     ]
    }
   ],
   "source": [
    "# Get these found points into the correct format\n",
    "dst_points = []\n",
    "\n",
    "for point in hexagon_points:\n",
    "    translated_point = point - center\n",
    "    rotated_point = np.dot(rotation_matrix, translated_point)\n",
    "    dst_points.append([int(rotated_point[0]+R), int(rotated_point[1]+R)])\n",
    "\n",
    "dst_points = np.array(dst_points)\n",
    "\n",
    "print(dst_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[129, 333],\n",
       "        [404, 162],\n",
       "        [701, 219],\n",
       "        [877, 525],\n",
       "        [607, 909],\n",
       "        [108, 747]]),\n",
       " array([[ 526, 1052],\n",
       "        [  70,  789],\n",
       "        [  70,  263],\n",
       "        [ 525,    0],\n",
       "        [ 981,  262],\n",
       "        [ 981,  788]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_points, dst_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute homography matrix\n",
    "H, _ = cv2.findHomography(src_points, dst_points)\n",
    "\n",
    "# Apply homography to warp the real test_image to the ideal Catan board's perspective\n",
    "warped_image = cv2.warpPerspective(test_image, H, (1052, 1052))\n",
    "\n",
    "showImage(warped_image, \"Homographied!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bb(image, center_point, sl, color):\n",
    "    \"\"\"\n",
    "    image: the image to draw the bounding box on\n",
    "    center_point: the center point of the bounding box\n",
    "    sl: side length of the square bounding box\n",
    "    color: scalar color of the bounding box to be\n",
    "    \"\"\"\n",
    "    tl_corner = (center_point[0] - int(sl/2), center_point[1] - int(sl/2)) # top left corner\n",
    "    tr_corner = (center_point[0] + int(sl/2), center_point[1] - int(sl/2)) # top right corner\n",
    "    bl_corner = (center_point[0] - int(sl/2), center_point[1] + int(sl/2)) # bottom left corner\n",
    "    br_corner = (center_point[0] + int(sl/2), center_point[1] + int(sl/2)) # bottom right corner\n",
    "\n",
    "    # draw the bounding box\n",
    "    # cv2.line(image, tl_corner, tr_corner, color, 3)\n",
    "    # cv2.line(image, tr_corner, br_corner, color, 3)\n",
    "    # cv2.line(image, br_corner, bl_corner, color, 3)\n",
    "    # cv2.line(image, bl_corner, tl_corner, color, 3)\n",
    "\n",
    "    return tl_corner[0], tl_corner[1], br_corner[0], br_corner[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_SL = 65 ## bounding box side length\n",
    "subimages = []\n",
    "\n",
    "for pt in dst_points:\n",
    "    delta_x = R - pt[0]\n",
    "    delta_y = R - pt[1]\n",
    "\n",
    "    ## Tests\n",
    "    # cv2.circle(warped_image, (int((R + (7/24)*delta_x)), int((R + (7/24)*delta_y))), 40, (0, 0, 0), 3)\n",
    "    x1, y1, x2, y2 = create_bb(warped_image, (int((R + (7/24)*delta_x)), int((R + (7/24)*delta_y))), BB_SL, (255, 0, 0))\n",
    "    subimage1 = warped_image[y1:y2, x1:x2]\n",
    "    # cv2.circle(warped_image, (int((R + (3/5)*delta_x)), int((R + (3/5)*delta_y))), 40, (0, 0, 0), 3)\n",
    "    x1, y1, x2, y2 = create_bb(warped_image, (int((R + (3/5)*delta_x)), int((R + (3/5)*delta_y))), BB_SL, (255, 0, 0))\n",
    "    subimage2 = warped_image[y1:y2, x1:x2]\n",
    "    \n",
    "    subimages.append(subimage1)\n",
    "    subimages.append(subimage2)\n",
    "\n",
    "showImage(warped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to catch the stragglers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dst_points)):\n",
    "    # Draw lines between every other corner\n",
    "    next_point_ind = i+2\n",
    "    if i+2 >= len(dst_points):\n",
    "        next_point_ind = i+2-len(dst_points)\n",
    "\n",
    "    pt1 = [dst_points[i][0], dst_points[i][1]]\n",
    "    pt2 = [dst_points[next_point_ind][0], dst_points[next_point_ind][1]]\n",
    "\n",
    "    # print(f\"pt1: {pt1} | pt2: {pt2}\")\n",
    "\n",
    "    # Draw circles at varying distances\n",
    "    delta_x = pt2[0] - pt1[0]\n",
    "    delta_y = pt2[1] - pt1[1]\n",
    "\n",
    "    # print(f\"delta_x: {delta_x} | delta_y: {delta_y}\")\n",
    "\n",
    "    # print(f\"One third: {(int((pt1[0] + (1/3)*delta_x)), int((pt1[1] + (1/3)*delta_y)))}\")\n",
    "    # print(f\"Two thirds: {(int((pt1[0] + (2/3)*delta_x)), int((pt1[1] + (2/3)*delta_y)))}\\n\")\n",
    "\n",
    "    ## Tests\n",
    "    cir_pt = (int((pt1[0] + (1/3)*delta_x)), int((pt1[1] + (1/3)*delta_y)))\n",
    "    # cv2.circle(warped_image, (int((pt1[0] + (1/3)*delta_x)), int((pt1[1] + (1/3)*delta_y))), 30, (255, 255, 255), 3)\n",
    "\n",
    "    ### Shift the circle toward the center a bit\n",
    "    xfc = R - cir_pt[0] # x distance from center\n",
    "    yfc = R - cir_pt[1] # y distance from center\n",
    "\n",
    "    shift_factor = 0.10 # Shifts the center point closer to the center by a factor if this much\n",
    "\n",
    "    shifted_x = int(cir_pt[0] + shift_factor * xfc)\n",
    "    shifted_y = int(cir_pt[1] + shift_factor * yfc)\n",
    "\n",
    "    # cv2.circle(warped_image, (int(shifted_x), int(shifted_y)), 40, (255, 255, 255), 3)\n",
    "    x1, y1, x2, y2 = create_bb(warped_image, (shifted_x, shifted_y), sl=BB_SL, color=(0, 255, 0))\n",
    "    subimage = warped_image[y1:y2, x1:x2]\n",
    "    subimages.append(subimage)\n",
    "\n",
    "showImage(warped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to ../images/cropped//00.jpg\n",
      "Image saved to ../images/cropped//01.jpg\n",
      "Image saved to ../images/cropped//02.jpg\n",
      "Image saved to ../images/cropped//03.jpg\n",
      "Image saved to ../images/cropped//04.jpg\n",
      "Image saved to ../images/cropped//05.jpg\n",
      "Image saved to ../images/cropped//06.jpg\n",
      "Image saved to ../images/cropped//07.jpg\n",
      "Image saved to ../images/cropped//08.jpg\n",
      "Image saved to ../images/cropped//09.jpg\n",
      "Image saved to ../images/cropped//10.jpg\n",
      "Image saved to ../images/cropped//11.jpg\n",
      "Image saved to ../images/cropped//12.jpg\n",
      "Image saved to ../images/cropped//13.jpg\n",
      "Image saved to ../images/cropped//14.jpg\n",
      "Image saved to ../images/cropped//15.jpg\n",
      "Image saved to ../images/cropped//16.jpg\n",
      "Image saved to ../images/cropped//17.jpg\n"
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "for img in subimages:\n",
    "    showImage(img)\n",
    "    if ind < 10:\n",
    "        saveImage(f\"0{ind}.jpg\", img, \"../images/cropped/\")\n",
    "    else:\n",
    "        saveImage(f\"{ind}.jpg\", img, \"../images/cropped/\")\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_shape: int, output_shape:int, stride=1) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # Conv layer 1\n",
    "        self.conv1 = nn.Conv2d(input_shape, \n",
    "                               output_shape, \n",
    "                               kernel_size=3,\n",
    "                               stride=stride,\n",
    "                               padding=1,\n",
    "                               bias=False)\n",
    "        # Batch norm 1\n",
    "        self.bn1 = nn.BatchNorm2d(output_shape)\n",
    "        # Activation\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Conv layer 2\n",
    "        self.conv2 = nn.Conv2d(output_shape, \n",
    "                               output_shape,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               bias=False)\n",
    "        # Batch norm 2\n",
    "        self.bn2 = nn.BatchNorm2d(output_shape)\n",
    "        \n",
    "        # Account for differences in stride length if not 1 & num filters\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or input_shape != output_shape:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(input_shape, output_shape,\n",
    "                          kernel_size=1, stride=stride,\n",
    "                          bias=False),\n",
    "                nn.BatchNorm2d(output_shape)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        logits = self.conv1(x)\n",
    "        logits = self.bn1(logits)\n",
    "        logits = self.relu(logits)\n",
    "        logits = self.conv2(logits)\n",
    "        logits = self.bn2(logits)\n",
    "        logits += self.downsample(identity)\n",
    "        logits = self.relu(logits)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_shape, block, layers, class_cnt):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.num_classes = class_cnt\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_shape, \n",
    "                               out_channels=64, \n",
    "                               kernel_size=3, \n",
    "                               stride=1, \n",
    "                               padding=1, \n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # Create 3 'blocks'\n",
    "        self.block1 = self.make_layer(block, 64, layers[0], stride=1)\n",
    "        self.block2 = self.make_layer(block, 128, layers[1], stride=2)\n",
    "        self.block3 = self.make_layer(block, 256, layers[2], stride=2)\n",
    "        # Average pooling\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(256, class_cnt)\n",
    "    def make_layer(self, block, output_shape, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, output_shape, stride))\n",
    "        self.in_channels = output_shape\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(output_shape, output_shape, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        logits = self.conv1(x)\n",
    "        # print(f\"x shape after conv block 1: {x.shape}\")\n",
    "        logits = self.bn1(logits)\n",
    "        # print(f\"x shape after batch norm 1: {x.shape}\")\n",
    "        logits = self.relu(logits)\n",
    "        logits = self.block1(logits)\n",
    "        # print(f\"x shape after res block 1: {x.shape}\")\n",
    "        logits = self.block2(logits)\n",
    "        # print(f\"x shape after res block 2: {x.shape}\")\n",
    "        logits = self.block3(logits)\n",
    "        # print(f\"x shape after res block 3: {x.shape}\")\n",
    "        logits = self.avg_pool(logits)\n",
    "        logits = logits.view(logits.size(0), -1)\n",
    "        logits = self.fc(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def slope(x1,y1,x2,y2):\n",
    "    ###finding slope\n",
    "    if x2!=x1:\n",
    "        return((y2-y1)/(x2-x1))\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "def y_intercept(x1,y1,x2,y2):\n",
    "    # y = mx+b OR b = y-mx\n",
    "    b = y1 - int(slope(x1, y1, x2, y2) * x1)\n",
    "    return b\n",
    "\n",
    "def calc_intersection(m1,b1,m2,b2):\n",
    "    # Create the coefficient matrices\n",
    "    a = np.array([[-m1, 1], [-m2, 1]])\n",
    "    b = np.array([b1, b2])\n",
    "    try:\n",
    "        solution = np.linalg.solve(a, b)\n",
    "    except:\n",
    "        solution = (0,0)\n",
    "\n",
    "    return solution\n",
    "\n",
    "def showImage(img, name=None):\n",
    "    if not name:\n",
    "        cv2.imshow(\"Image display\", img)\n",
    "    else:\n",
    "        cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def homography_board(image):\n",
    "    ## Get border image\n",
    "    # Resize to 1052x1052\n",
    "    image = cv2.resize(image, (1052, 1052))\n",
    "    # Convert to HSV\n",
    "    hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # Define the color range of the border\n",
    "    lower_blue = np.array([100, 150, 0])\n",
    "    upper_blue = np.array([140, 255, 255])\n",
    "    # Get the mask of just the blue regions\n",
    "    mask = cv2.inRange(hsv_img, lower_blue, upper_blue)\n",
    "    # Get the bitwise_and of the blue region (1 if blue, 0 if not)\n",
    "    blue_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "    # Format image so guassian blur and canny edge can be performed\n",
    "    gray_blue_region = cv2.cvtColor(blue_region, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply gaussian blur for edge detection\n",
    "    blurred_blue_region = cv2.GaussianBlur(gray_blue_region, (5,5), 0)\n",
    "    # Canny Edge Detection\n",
    "    edges = cv2.Canny(blurred_blue_region, 50, 150)\n",
    "\n",
    "    ## Hough Transform for perimiter lines\n",
    "    lines = []\n",
    "    thresh = 200\n",
    "    while len(lines) < 10:\n",
    "        lines=cv2.HoughLines(edges, 1, np.pi / 180, thresh)\n",
    "        if len(lines) >= 10:\n",
    "            break\n",
    "        else:\n",
    "            thresh -= 5\n",
    "\n",
    "    # Find overlapping lines from hough transform\n",
    "    min_rho_diff = 10 # the minimum distance between two lines to determine if they are for the same side\n",
    "    overlapping_indexes = set()\n",
    "\n",
    "    while len(lines) - len(overlapping_indexes) > 6:\n",
    "        for i in range(len(lines)):\n",
    "            rho, _ = lines[i, 0]\n",
    "            for j in range(i+1, len(lines)):\n",
    "                rho2, _ = lines[j, 0]\n",
    "                if abs(rho-rho2) < min_rho_diff:\n",
    "                    overlapping_indexes.add(j)\n",
    "        min_rho_diff += 1\n",
    "    perimiter_lines = [] # these are the actual perimiter lines after overlap is removed\n",
    "    # Get the perimiter lines\n",
    "    for i in range(len(lines)):\n",
    "        if i not in overlapping_indexes:\n",
    "            perimiter_lines.append(lines[i])\n",
    "\n",
    "    ## Finding the perimiter POINTS from the perimiter lines\n",
    "    line_coords = []\n",
    "    for index, line in enumerate(perimiter_lines):\n",
    "        rho, theta = line[0]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "        line_coords.append([(x1, y1), (x2, y2)])\n",
    "    \n",
    "    # Get the line equations\n",
    "    line_equations = []\n",
    "    for line in line_coords:\n",
    "        try:\n",
    "            line_equations.append((slope(line[0][0], line[0][1], line[1][0], line[1][1]), \n",
    "                                   y_intercept(line[0][0], line[0][1], line[1][0], line[1][1])))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Get perimiter points\n",
    "    perimeter_points = []\n",
    "    image_height, image_width, _ = image.shape\n",
    "    for ind, line_one in enumerate(line_equations):\n",
    "        for line_two in line_equations[ind+1:]:\n",
    "            perimeter_point = calc_intersection(line_one[0], line_one[1],\n",
    "                                                line_two[0], line_two[1])\n",
    "            if perimeter_point[0] == 0 and perimeter_point[1] == 0:\n",
    "                pass\n",
    "            elif perimeter_point[0] >= 0 and perimeter_point[0] <= image_width and perimeter_point[1] >= 0 and perimeter_point[1] <= image_height:\n",
    "                perimeter_points.append((round(perimeter_point[0]), \n",
    "                                          round(perimeter_point[1])))\n",
    "\n",
    "def pred_nums_on_resnet(images) -> list:\n",
    "    \"\"\"\n",
    "    images - list of subimages of the numbers of a Catan board\n",
    "\n",
    "    returns a list of labels in the order the images are passed in\n",
    "    \"\"\"\n",
    "    # Set up and load the model\n",
    "    CLASS_NAMES = [\"two\", \"three\", \"four\", \"five\", \"six\", \n",
    "                   \"eight\", \"nine\", \"ten\", \"eleven\", \"twelve\"]\n",
    "    CLASS_CNT = len(CLASS_NAMES) # ten numbers to be predicted\n",
    "    MODEL_SAVE_PATH = \"../models/catanist_resnet2.pth\"\n",
    "    LABELS = []\n",
    "\n",
    "    # Device agnostic code\n",
    "    device = (\"cuda\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "            )\n",
    "\n",
    "    resnet_model = ResNet(input_shape=3, \n",
    "                        block=BasicBlock,\n",
    "                        layers=[2, 2, 2],\n",
    "                        class_cnt=CLASS_CNT).to(device)\n",
    "\n",
    "    resnet_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
    "    resnet_model.to(device)\n",
    "\n",
    "    # Define the image transform\n",
    "    input_transform = transforms.Compose([\n",
    "        transforms.Resize(size=(64, 64)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    # Put the model into eval mode\n",
    "    resnet_model.eval()\n",
    "    for image in images:\n",
    "        transformed_img = input_transform(Image.fromarray(image[:3, :, :]))\n",
    "        with torch.inference_mode():\n",
    "            img_pred = resnet_model((transformed_img.unsqueeze(0)).to(device))\n",
    "        # Logits -> Predictions probabilites -> Prediction labels -> class name\n",
    "        img_label = CLASS_NAMES[torch.argmax(torch.softmax(img_pred, dim=1), dim=1)]\n",
    "        LABELS.append(img_label)\n",
    "\n",
    "    return LABELS\n",
    "\n",
    "def show_predictions(subimages, labels):\n",
    "    for i in range(len(subimages)):\n",
    "        showImage(subimages[i], str(labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mpred_nums_on_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m show_predictions(subimages, labels)\n",
      "Cell \u001b[0;32mIn[39], line 159\u001b[0m, in \u001b[0;36mpred_nums_on_resnet\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m    157\u001b[0m resnet_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[0;32m--> 159\u001b[0m     transformed_img \u001b[38;5;241m=\u001b[39m input_transform(\u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mfromarray(image[:\u001b[38;5;241m3\u001b[39m, :, :]))\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m    161\u001b[0m         img_pred \u001b[38;5;241m=\u001b[39m resnet_model((transformed_img\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "labels = pred_nums_on_resnet(subimages)\n",
    "show_predictions(subimages, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
